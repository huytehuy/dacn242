{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52890889-1171-4c7a-a051-10a7dc381f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db9af42-2329-47db-a8d0-ec93fa547a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./Data_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f11f6db3-bc00-42e2-8ebe-275207889134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Hàm tải và lưu ảnh\n",
    "def tai_va_luu_anh(url, path_to_save):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "\n",
    "            # Kiểm tra nếu ảnh là trong chế độ RGBA, chuyển nó sang RGB\n",
    "            if img.mode == 'RGBA':\n",
    "                img = img.convert('RGB')\n",
    "\n",
    "            img.save(path_to_save)\n",
    "            print(f\"Đã lưu: {path_to_save}\")\n",
    "        else:\n",
    "            print(f\"Lỗi khi tải ảnh từ {url}: Status code {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Không thể tải ảnh từ {url}. Lỗi: {e}\")\n",
    "\n",
    "# Giả sử `base_dir` và `data_dict` đã được định nghĩa\n",
    "# Duyệt qua từ điển và tải ảnh\n",
    "for label, urls in data_dict.items():\n",
    "    # Tạo thư mục cho mỗi label nếu chưa tồn tại\n",
    "    label_dir = os.path.join(base_dir, label)  # Sử dụng trực tiếp tên label\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "    \n",
    "    # Tải và lưu mỗi ảnh trong list\n",
    "    for i, url in enumerate(urls):\n",
    "        file_name = f\"anh_{i}.jpg\"  # Đặt tên file\n",
    "        path_to_save = os.path.join(label_dir, file_name)\n",
    "        tai_va_luu_anh(url, path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fa26698-a59b-4126-bfb6-e2b7fc98f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data_images\\Iphone 11\n",
      "./Data_images\\Iphone 13\n",
      "./Data_images\\Iphone 13 Pro\n",
      "./Data_images\\Iphone 14\n",
      "./Data_images\\Iphone 14 Pro\n",
      "./Data_images\\Iphone 15\n",
      "./Data_images\\Iphone 15 Pro\n",
      "./Data_images\\Oppo Reno11 F\n",
      "./Data_images\\Samsung Galaxy M34\n",
      "./Data_images\\Samsung Galaxy S23\n",
      "./Data_images\\Samsung Galaxy S23 Ultra\n",
      "./Data_images\\Samsung Galaxy Z Fold5\n",
      "./Data_images\\Samsung Galaxy Z Fold6\n",
      "./Data_images\\Tcl Google Tv\n",
      "./Data_images\\Xiaomi Poco X6 Pro\n",
      "./Data_images\\Xiaomi Redmi Note 13\n",
      "Dữ liệu huấn luyện: (951, 128, 128, 3), Nhãn huấn luyện: (951,)\n",
      "Dữ liệu kiểm tra: (115, 128, 128, 3), Nhãn kiểm tra: (115,)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "    \n",
    "def doc_va_chuyen_doi_anh_voi_nhan(thu_muc, label, target_size=(128, 128)):\n",
    "    data_arrays = []\n",
    "    labels = []\n",
    "    \n",
    "    # Include both JPG and PNG files in the search pattern\n",
    "    for file_path in glob.glob(os.path.join(thu_muc, \"*.*\")):\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img = Image.open(file_path).convert('RGB')  # Convert to RGB\n",
    "            img_resized = img.resize(target_size)\n",
    "            img_array = np.array(img_resized) / 255.0\n",
    "            #print(img_array.shape)  # Debugging to check shape\n",
    "            data_arrays.append(img_array)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(data_arrays), np.array(labels)\n",
    "\n",
    "data_train = []\n",
    "labels_train = []\n",
    "data_test = []\n",
    "labels_test = []\n",
    "\n",
    "# Sử dụng hàm cho mỗi thư mục nhãn\n",
    "for label in os.listdir(base_dir):\n",
    "    full_path = os.path.join(base_dir, label)\n",
    "    print(full_path)\n",
    "    data, labels = doc_va_chuyen_doi_anh_voi_nhan(full_path, label)\n",
    "    \n",
    "    # Giả sử chia 90% đầu làm dữ liệu huấn luyện và 10% còn lại làm dữ liệu kiểm tra\n",
    "    split_idx = int(len(data) * 0.9)\n",
    "    data_train.extend(data[:split_idx])\n",
    "    labels_train.extend(labels[:split_idx])\n",
    "    \n",
    "    data_test.extend(data[split_idx:])\n",
    "    labels_test.extend(labels[split_idx:])\n",
    "\n",
    "# Chuyển các list thành numpy arrays\n",
    "data_train = np.array(data_train)\n",
    "labels_train = np.array(labels_train)\n",
    "data_test = np.array(data_test)\n",
    "labels_test = np.array(labels_test)\n",
    "\n",
    "print(f\"Dữ liệu huấn luyện: {data_train.shape}, Nhãn huấn luyện: {labels_train.shape}\")\n",
    "print(f\"Dữ liệu kiểm tra: {data_test.shape}, Nhãn kiểm tra: {labels_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f43b177-a43b-4ec9-885f-7baf8b553e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 128, 128, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef73b070-8150-4151-b0e5-ecfe35282a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iphone 11', 'Iphone 11', 'Iphone 11', 'Iphone 11', 'Iphone 11',\n",
       "       'Iphone 11', 'Iphone 11', 'Iphone 11', 'Iphone 11', 'Iphone 11',\n",
       "       'Iphone 13', 'Iphone 13', 'Iphone 13', 'Iphone 13', 'Iphone 13',\n",
       "       'Iphone 13', 'Iphone 13', 'Iphone 13 Pro', 'Iphone 13 Pro',\n",
       "       'Iphone 13 Pro', 'Iphone 13 Pro', 'Iphone 13 Pro', 'Iphone 13 Pro',\n",
       "       'Iphone 13 Pro', 'Iphone 13 Pro', 'Iphone 14', 'Iphone 14',\n",
       "       'Iphone 14', 'Iphone 14', 'Iphone 14', 'Iphone 14', 'Iphone 14',\n",
       "       'Iphone 14 Pro', 'Iphone 14 Pro', 'Iphone 14 Pro', 'Iphone 14 Pro',\n",
       "       'Iphone 14 Pro', 'Iphone 14 Pro', 'Iphone 14 Pro', 'Iphone 14 Pro',\n",
       "       'Iphone 15', 'Iphone 15', 'Iphone 15', 'Iphone 15', 'Iphone 15',\n",
       "       'Iphone 15', 'Iphone 15 Pro', 'Iphone 15 Pro', 'Iphone 15 Pro',\n",
       "       'Iphone 15 Pro', 'Iphone 15 Pro', 'Iphone 15 Pro', 'Iphone 15 Pro',\n",
       "       'Iphone 15 Pro', 'Iphone 15 Pro', 'Iphone 15 Pro', 'Oppo Reno11 F',\n",
       "       'Oppo Reno11 F', 'Oppo Reno11 F', 'Oppo Reno11 F', 'Oppo Reno11 F',\n",
       "       'Oppo Reno11 F', 'Oppo Reno11 F', 'Oppo Reno11 F',\n",
       "       'Samsung Galaxy M34', 'Samsung Galaxy M34', 'Samsung Galaxy M34',\n",
       "       'Samsung Galaxy M34', 'Samsung Galaxy M34', 'Samsung Galaxy S23',\n",
       "       'Samsung Galaxy S23', 'Samsung Galaxy S23', 'Samsung Galaxy S23',\n",
       "       'Samsung Galaxy S23', 'Samsung Galaxy S23 Ultra',\n",
       "       'Samsung Galaxy S23 Ultra', 'Samsung Galaxy S23 Ultra',\n",
       "       'Samsung Galaxy S23 Ultra', 'Samsung Galaxy S23 Ultra',\n",
       "       'Samsung Galaxy Z Fold5', 'Samsung Galaxy Z Fold5',\n",
       "       'Samsung Galaxy Z Fold5', 'Samsung Galaxy Z Fold5',\n",
       "       'Samsung Galaxy Z Fold5', 'Samsung Galaxy Z Fold5',\n",
       "       'Samsung Galaxy Z Fold5', 'Samsung Galaxy Z Fold5',\n",
       "       'Samsung Galaxy Z Fold5', 'Samsung Galaxy Z Fold6',\n",
       "       'Samsung Galaxy Z Fold6', 'Samsung Galaxy Z Fold6',\n",
       "       'Samsung Galaxy Z Fold6', 'Samsung Galaxy Z Fold6',\n",
       "       'Samsung Galaxy Z Fold6', 'Tcl Google Tv', 'Tcl Google Tv',\n",
       "       'Tcl Google Tv', 'Tcl Google Tv', 'Tcl Google Tv', 'Tcl Google Tv',\n",
       "       'Xiaomi Poco X6 Pro', 'Xiaomi Poco X6 Pro', 'Xiaomi Poco X6 Pro',\n",
       "       'Xiaomi Poco X6 Pro', 'Xiaomi Poco X6 Pro', 'Xiaomi Poco X6 Pro',\n",
       "       'Xiaomi Redmi Note 13', 'Xiaomi Redmi Note 13',\n",
       "       'Xiaomi Redmi Note 13', 'Xiaomi Redmi Note 13',\n",
       "       'Xiaomi Redmi Note 13', 'Xiaomi Redmi Note 13',\n",
       "       'Xiaomi Redmi Note 13', 'Xiaomi Redmi Note 13',\n",
       "       'Xiaomi Redmi Note 13'], dtype='<U24')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07404be6-b706-4417-9342-52174520ade6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4\n",
      "  4  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  2  2  2  2  2  2  2\n",
      "  2  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  5  5  5  5  5  5  6  6\n",
      "  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  8  8  8  8  8  9  9  9\n",
      "  9  9 10 10 10 10 10 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 13 13\n",
      " 13 13 13 13 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Tạo một encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Đưa nhãn văn bản về dạng số nguyên\n",
    "labels_train_encoded = encoder.fit_transform(labels_train)\n",
    "labels_test_encoded = encoder.fit_transform(labels_test)\n",
    "# In nhãn sau khi được mã hóa để kiểm tra\n",
    "print(labels_train_encoded)\n",
    "print(labels_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c0ec265-6f9c-45f6-8aa7-db904dba2df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\huuhi\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f15ffd29-9beb-42a6-9c32-4ae2cf629e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Chuyển đổi nhãn sang dạng one-hot\n",
    "labels_train_one_hot = to_categorical(labels_train_encoded)\n",
    "labels_test_one_hot = to_categorical(labels_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8117a684-5a05-42d0-9d21-1ec9d99439f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9dc1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe57fb6d-9bbe-4c30-a992-0f33f2c22de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "entries = os.listdir(base_dir)\n",
    "folder_count = sum(os.path.isdir(os.path.join(base_dir, entry)) for entry in entries)\n",
    "print(folder_count)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(128, 128, 3)),  # Sử dụng Input layer để xác định kích thước đầu vào\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(folder_count, activation='softmax')  # `len(data_dict)` là số lớp\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94c0ad5c-b334-4138-8742-2f2cc1793d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 472ms/step - accuracy: 0.0816 - loss: 3.3648\n",
      "Epoch 2/11\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 463ms/step - accuracy: 0.1293 - loss: 2.6876\n",
      "Epoch 3/11\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 413ms/step - accuracy: 0.2311 - loss: 2.4575\n",
      "Epoch 4/11\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 414ms/step - accuracy: 0.3488 - loss: 2.1349\n",
      "Epoch 5/11\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 433ms/step - accuracy: 0.5014 - loss: 1.5319\n",
      "Epoch 6/11\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 415ms/step - accuracy: 0.6903 - loss: 1.0467\n",
      "Epoch 7/11\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 419ms/step - accuracy: 0.7637 - loss: 0.7921\n",
      "Epoch 8/11\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 437ms/step - accuracy: 0.8511 - loss: 0.4984\n",
      "Epoch 9/11\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 422ms/step - accuracy: 0.9027 - loss: 0.3667\n",
      "Epoch 10/11\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 433ms/step - accuracy: 0.9172 - loss: 0.2951\n",
      "Epoch 11/11\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 444ms/step - accuracy: 0.9440 - loss: 0.2178\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((data_train, labels_train_one_hot)).batch(32).repeat()\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((data_test, labels_test_one_hot)).batch(32).repeat()\n",
    "\n",
    "# Huấn luyện mô hình validation_data=(data_test, labels_test_one_hot)\n",
    "history = model.fit(\n",
    "    data_train, labels_train_one_hot,\n",
    "    epochs=11, # Số lượng bước huấn luyện mỗi epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f68bd09-d5d0-4e4b-8c10-606d14c59e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'compile_metrics']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdbbb542-d387-4ca1-a4c0-94956cd145b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.3315 - loss: 3.8739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.881770133972168, 0.365217387676239]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data_test,labels_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "611a0886-0eef-4a85-ba16-a6868ddfa491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 378ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.30      0.33        10\n",
      "           1       0.25      0.29      0.27         7\n",
      "           2       0.29      0.25      0.27         8\n",
      "           3       0.75      0.43      0.55         7\n",
      "           4       0.36      0.50      0.42         8\n",
      "           5       0.50      0.33      0.40         6\n",
      "           6       0.30      0.30      0.30        10\n",
      "           7       0.50      0.12      0.20         8\n",
      "           8       0.33      0.20      0.25         5\n",
      "           9       0.33      0.20      0.25         5\n",
      "          10       0.25      0.40      0.31         5\n",
      "          11       0.15      0.22      0.18         9\n",
      "          12       0.29      0.33      0.31         6\n",
      "          13       0.83      0.83      0.83         6\n",
      "          14       0.25      0.50      0.33         6\n",
      "          15       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.37       115\n",
      "   macro avg       0.40      0.37      0.37       115\n",
      "weighted avg       0.40      0.37      0.37       115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "predictions = model.predict(data_test)\n",
    "\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "actual_classes = np.argmax(labels_test_one_hot, axis=1)\n",
    "\n",
    "report = classification_report(actual_classes, predicted_classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd88c74c-3334-4d92-a9f3-aa79dd184510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3 0 0 0 0 0 0 1 0 1 0 0 0 2 0]\n",
      " [0 2 1 0 1 1 1 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 2 0 0 0 1 0 0 0 0 2 0 1 1 0]\n",
      " [0 1 0 3 0 1 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 1 0 4 0 0 0 0 0 0 1 0 0 1 1]\n",
      " [1 1 0 0 0 2 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 3 0 3 0 0 0 0 1 0 0 2 1]\n",
      " [0 0 0 1 2 0 1 1 1 0 0 0 1 0 0 1]\n",
      " [0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 1 2 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 2 1 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 1 2 2 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 2 2 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 5 0 0]\n",
      " [0 0 2 0 0 0 1 0 0 0 0 0 0 0 3 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 2 0 0 0 6]]\n",
      "True Positives:  [3 2 2 3 4 2 3 1 1 1 2 2 2 5 3 6]\n",
      "False Positives:  [ 5  6  5  1  7  2  7  1  2  2  6 11  5  1  9  3]\n",
      "True Negatives:  [100 102 102 107 100 107  98 106 108 108 104  95 104 108 100 103]\n",
      "False Negatives:  [7 5 6 4 4 4 7 7 4 4 3 7 4 1 3 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Giả sử predicted_classes là nhãn dự đoán từ mô hình của bạn\n",
    "# và actual_classes là nhãn thực tế của tập kiểm tra\n",
    " # [[41  7  1  0  2]\n",
    " # [ 1  3  1  3  3]\n",
    " # [ 8  0 34  1  8]\n",
    " # [ 7  1  1 15  5]\n",
    " # [ 4  0  7  7 32]]\n",
    "# Tính ma trận nhầm lẫn\n",
    "cm = confusion_matrix(actual_classes, predicted_classes)\n",
    "\n",
    "# In ma trận nhầm lẫn\n",
    "print(cm)\n",
    "\n",
    "# Tính TP, TN, FP, FN cho mỗi lớp\n",
    "TP = np.diag(cm)\n",
    "FP = cm.sum(axis=0) - np.diag(cm)\n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# In ra số lượng TP, TN, FP, FN cho mỗi lớp\n",
    "print(\"True Positives: \", TP)\n",
    "print(\"False Positives: \", FP)\n",
    "print(\"True Negatives: \", TN)\n",
    "print(\"False Negatives: \", FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b18e059b-7dcb-405a-84ea-cbb06a24ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('e-commerce-model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "240aa009-49c4-4648-958a-2fbdeb632a3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Lưu encoder\n",
    "joblib.dump(encoder, 'label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90dd4420-af56-47e3-9a07-60998395b42b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "only"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Xác suất dự đoán cho mỗi nhãn:\n",
      "Iphone 11: 0.00%\n",
      "Iphone 13: 0.11%\n",
      "Iphone 13 Pro: 0.08%\n",
      "Iphone 14: 0.88%\n",
      "Iphone 14 Pro: 98.34%\n",
      "Iphone 15: 0.04%\n",
      "Iphone 15 Pro: 0.08%\n",
      "Oppo Reno11 F: 0.03%\n",
      "Samsung Galaxy M34: 0.05%\n",
      "Samsung Galaxy S23: 0.00%\n",
      "Samsung Galaxy S23 Ultra: 0.02%\n",
      "Samsung Galaxy Z Fold5: 0.28%\n",
      "Samsung Galaxy Z Fold6: 0.01%\n",
      "Tcl Google Tv: 0.00%\n",
      "Xiaomi Poco X6 Pro: 0.03%\n",
      "Xiaomi Redmi Note 13: 0.04%\n"
     ]
    }
   ],
   "source": [
    "# run this cell\n",
    "import requests\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "url = 'http://localhost:3000/Imgsearch'\n",
    "\n",
    "# Tải LabelEncoder\n",
    "encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Chuẩn bị ảnh\n",
    "img_path = './uploads/test1.jpg'\n",
    "img = image.load_img(img_path, target_size=(128, 128))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0\n",
    "\n",
    "# Dự đoán\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Lấy tất cả nhãn từ encoder\n",
    "all_labels = encoder.classes_\n",
    "\n",
    "# Hiển thị xác suất dự đoán cho mỗi nhãn\n",
    "print(\"Xác suất dự đoán cho mỗi nhãn:\")\n",
    "for label, prob in zip(all_labels, predictions[0]):\n",
    "        if prob * 100 > 0:  # \n",
    "            print(f\"{label}: {prob*100:.2f}%\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
